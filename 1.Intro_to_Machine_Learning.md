Intro to Machine Learning
================
PK (Kasidit) Ratanavijai
07/12/2019

## Introduction

Machine Learning is *an algorithm that takes **feature** value as
**input** and returns a prediction for the **outcome** when we don’t
know the outcome.* In machine learning, data comes in the form of **the
outcome** we want to predict and **the features** that we will use to
predict the outcome.

The machine-learning approach is to train an algorithm using a dataset
for which we do know **the outcome**, and then apply this algorithm in
the future to make a prediction when we don’t know the outcome.

Here we’ll use Y as **outcomes** and X as **features.** or predictors.

When the outcome is categorical, we refer to the machine-learning task
as classification. Our predictions will be categorical just like our
outcomes, and they will be either correct or incorrect. When the outcome
is continuous, we’ll refer to the task as prediction. In this case, our
prediction will not be either right or wrong. Instead, we will make an
error which is the difference between the prediction and the actual
outcome.

Let consider a use case example.

How post office use Machine Learning to sort coming letters by zip code.

1.  Identify the feature and the outcome. In this case,

<!-- end list -->

    * The feature is each pixel in a image of a number from the lettters
    * The outcome is number (0,1,2,3,4,5,6,7,8,9)

2.  A set of images of written digits that have already been read and
    assigned a number (outcome) by a human is called training data

## Basic Concept

### The overall accuracy

Let’s start with a simple example. We predict sex (male of female) using
his or her heights. Again, start by indentify outcome and predictor. In
this case:

``` r
x = heights$height
y = heights$sex
```

Then ,we randomly split out the data that already has outcomes into 2
sets. The first set use to develop the algorithm as the training set,
the other one will be use to evaluate our algorithm after we finish
constructing.

The caret package includes the function “createDataPartition” that helps
us generate indexes for randomly splitting the data into training and
test sets.

``` r
set.seed(2)
test = createDataPartition(y, times = 1, p =0.5, list = FALSE)
#assign test and train sets.
train_set = heights[-test,]
test_set = heights[test,]
```

Once we’re done developing the algorithm, we will freeze it, and
evaluate it using the test set. The simplest way to evaluate the
algorithm when the outcomes are categorical is simply by reporting the
proportion of cases that were correctly predicted in the test set. This
is called **overall accuracy**

**Let try predicting**  
Exploratory data as it suggests we can because on average, males are
slightly taller than females.Let’s try a simple approach.Predict male if
height is within two standard deviations from the average male.

``` r
y_hat = ifelse(x>64 , "Male", "Female") %>%
  factor(levels = levels(test_set$sex))
# the overall accuracy is
mean( y == y_hat)
```

    ## [1] 0.8266667

However, the overall accuracy can be deceptive measurement.If we compute
the accuracy separately for each sex, we get that we get a very high
accuracy for males, 93%, but a very low accuracy for females, 42%.
Because There are more males in the data sets than females.

There are several metrics that we can use to evaluate an algorithm in a
way that prevalence does not cloud our assessments. And these can all be
derived from what is called the confusion matrix. A general improvement
to using overall accuracy is to study sensitivity and specificity
separately.

In general, sensitivity is defined as the ability of an algorithm to
predict a positive outcome when the actual outcome is positive. And,
specificity as the ability of an algorithm to not predict the positive,
when the actual outcome is not positive.

Wikipedia summary
:<https://en.wikipedia.org/wiki/Sensitivity_and_specificity>  
Sensitivity (also called the true positive rate, the recall, or
probability of detection\[1\] in some fields) measures the proportion of
actual positives that are correctly identified as such (e.g., the
percentage of sick people who are correctly identified as having the
condition). Specificity (also called the true negative rate) measures
the proportion of actual negatives that are correctly identified as such
(e.g., the percentage of healthy people who are correctly identified as
not having the condition).

``` r
confusionMatrix(data  = y_hat , reference = y)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction Female Male
    ##     Female    106   50
    ##     Male      132  762
    ##                                           
    ##                Accuracy : 0.8267          
    ##                  95% CI : (0.8024, 0.8491)
    ##     No Information Rate : 0.7733          
    ##     P-Value [Acc > NIR] : 1.271e-05       
    ##                                           
    ##                   Kappa : 0.437           
    ##                                           
    ##  Mcnemar's Test P-Value : 1.924e-09       
    ##                                           
    ##             Sensitivity : 0.4454          
    ##             Specificity : 0.9384          
    ##          Pos Pred Value : 0.6795          
    ##          Neg Pred Value : 0.8523          
    ##              Prevalence : 0.2267          
    ##          Detection Rate : 0.1010          
    ##    Detection Prevalence : 0.1486          
    ##       Balanced Accuracy : 0.6919          
    ##                                           
    ##        'Positive' Class : Female          
    ## 

We can see the despite the high overall accuracy the Sensitivity is
lower that half. This is because the prevalance of male in data set.

### The balanced accuracy

One metric that is preferred over overall accuracy is the average of
specificity and sensitivity,referred to as the balanced accuracy.

We define ![1](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cbeta)
to adjust weight on sensitivity (true positive) and specificity(true
negative) rate depend on case. The F-1 score formula is
:

![2](https://latex.codecogs.com/gif.latex?%5Cdpi%7B150%7D%20%5Cfrac%7B1%7D%7B%20%5Cfrac%7B%5Cbeta%5E%7B2%7D%7D%7B1+%5Cbeta%5E%7B2%7D%7D%5Cfrac%7B1%7D%7Brecall%7D%20+%20%5Cfrac%7B1%7D%7B1+%5Cbeta%5E%7B2%7D%7D%5Cfrac%7B1%7D%7Bprecision%7D%20%7D)

So let’s rebuild our prediction algorithm, but this time maximizing the
F score instead of overall accuracy.

``` r
cutoff = seq(61,70)
F_1 = map_dbl (cutoff, function(x){
  y_hat = ifelse(train_set$height > x , "Male", "Female") %>%
    factor(levels = levels(test_set$sex))
  F_meas(data = y_hat , reference = factor(train_set$sex))
})

best_cutoff = cutoff[which.max(F_1)] ;best_cutoff
```

    ## [1] 66

66 inches cutoff balances the specificity and sensitivity of our
confusion matrix as seen here.

``` r
y_hat = ifelse(test_set$height > best_cutoff, "Male", "Female") %>%
  factor(levels = levels(test_set$sex))
  confusionMatrix(data  = y_hat , reference = test_set$sex)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction Female Male
    ##     Female     82   77
    ##     Male       37  329
    ##                                           
    ##                Accuracy : 0.7829          
    ##                  95% CI : (0.7451, 0.8174)
    ##     No Information Rate : 0.7733          
    ##     P-Value [Acc > NIR] : 0.3221872       
    ##                                           
    ##                   Kappa : 0.4464          
    ##                                           
    ##  Mcnemar's Test P-Value : 0.0002595       
    ##                                           
    ##             Sensitivity : 0.6891          
    ##             Specificity : 0.8103          
    ##          Pos Pred Value : 0.5157          
    ##          Neg Pred Value : 0.8989          
    ##              Prevalence : 0.2267          
    ##          Detection Rate : 0.1562          
    ##    Detection Prevalence : 0.3029          
    ##       Balanced Accuracy : 0.7497          
    ##                                           
    ##        'Positive' Class : Female          
    ## 

### Summary

Nothice that both sensitivity and specificity are relatively high. We
have built our first machine learning algorithm. It takes height as a
predictor, and predicts female if you are 66 inches or shorter.
